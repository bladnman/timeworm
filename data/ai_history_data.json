{
    "meta": {
        "title": "The Architecture of Minds: A Comprehensive History of Artificial Intelligence and Computing",
        "version": "1.2.0",
        "generated_date": "2025-12-06",
        "overview": "The history of artificial intelligence is not merely a chronicle of engineering; it is the physical manifestation of humanity’s oldest philosophical inquiry: Can thought be mechanized? This dataset traces the arc from the geared brass of antiquity to the neural superclusters of late 2025.",
        "attribution": "Expanded dataset based on 'The Architecture of Minds' research parameters."
    },
    "groups": [
        {
            "id": "grp_ancient",
            "title": "Part I: The Analog Origins and the Mechanization of Logic",
            "date_range": "Antiquity – 1899",
            "description": "Before electricity became the medium of thought, logic was constrained by the speed of gears and the friction of physical matter. Yet, the conceptual frameworks established in this era—programmability, binary logic, and simulation—remain the bedrock of modern AI."
        },
        {
            "id": "grp_electronic_dawn",
            "title": "Part II: The Electronic Dawn and the Birth of AI",
            "date_range": "1900 – 1959",
            "description": "The first half of the 20th century saw the transition from mechanical gears to vacuum tubes. The pressures of World War II accelerated the development of high-speed calculation, leading to the first machines that could process information at electronic speeds."
        },
        {
            "id": "grp_golden_winter",
            "title": "Part III: The Golden Age, The Winter, and The Resurgence",
            "date_range": "1960 – 2011",
            "description": "The middle decades of AI history were defined by a conflict between two schools of thought: Symbolic AI (which believed intelligence was the manipulation of symbols and rules) and Connectionism (which believed intelligence emerged from networks of simple neurons)."
        },
        {
            "id": "grp_transformer",
            "title": "Part IV: The Transformer Era and Generative AI",
            "date_range": "2012 – 2023",
            "description": "Following AlexNet, the field moved fast. The introduction of the Transformer architecture in 2017 solved the problem of scaling, allowing models to ingest the entire internet."
        },
        {
            "id": "grp_reasoning",
            "title": "Part V: The Age of Reasoning and Agents",
            "date_range": "2024 – Late 2025",
            "description": "By 2024, the 'scaling laws' (just adding more data/compute) began to show diminishing returns. The frontier shifted to Test-Time Compute (letting the model 'think' before answering) and Multimodality (native audio/video)."
        }
    ],
    "events": [
        {
            "id": "evt_jacquard",
            "title": "The Jacquard Loom",
            "date_display": "1804",
            "date_start": "1804-01-01",
            "group_ids": [
                "grp_ancient"
            ],
            "type": "Hardware",
            "innovator": "Joseph Marie Jacquard",
            "innovation": "Programmability via Punched Cards",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/0/09/Jacquard.loom.cards.jpg",
                "https://upload.wikimedia.org/wikipedia/commons/5/55/A_Jacquard_loom_showing_information_punchcards%2C_National_Museum_of_Scotland.jpg"
            ],
            "description": "Joseph Marie Jacquard did not invent the loom, but he invented the concept of 'software' to control it. By using a series of stiff pasteboard cards with punched holes, he created a system where the pattern of the weave was stored independently of the machine itself. The presence or absence of a hole determined whether a thread would be raised or lowered—a binary system (0 or 1) implemented in cardboard. This was a critical conceptual leap: the machine (hardware) was general-purpose, and the cards (software) specialized it. This mechanism directly inspired Charles Babbage’s design for the Analytical Engine.",
            "metrics": {
                "mechanism": "Binary Punched Cards",
                "impact": "Industrial Automation"
            },
            "links": [
                {
                    "title": "Science Museum Group: Jacquard Loom",
                    "url": "https://collection.sciencemuseumgroup.org.uk/"
                }
            ]
        },
        {
            "id": "evt_analytical_engine",
            "title": "The Analytical Engine and 'Note G'",
            "date_display": "1837 – 1843",
            "date_start": "1837-01-01",
            "date_end": "1843-09-01",
            "group_ids": [
                "grp_ancient"
            ],
            "type": "Conceptual Design / Algorithm",
            "innovator": "Charles Babbage, Ada Lovelace",
            "innovation": "First General-Purpose Computer Design & Algorithm",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/c/cc/Babbages_Analytical_Engine%2C_1834-1871._%289660574685%29.jpg",
                "https://upload.wikimedia.org/wikipedia/commons/0/0d/PunchedCardsAnalyticalEngine.jpg"
            ],
            "description": "While the Difference Engine was a calculator, the Analytical Engine was a computer. Babbage designed it with a 'Store' (memory) and a 'Mill' (CPU), capable of conditional branching and loops, making it Turing-complete by modern standards. However, it was Ada Lovelace who saw the true potential. In her translation of a lecture on the engine, she added 'Note G,' which contained a stepwise algorithm for calculating Bernoulli numbers—the first computer program. More importantly, she famously observed that the engine 'might act upon other things besides number,' theorizing that if music or letters were converted to symbols, the machine could compose or reason, effectively predicting the field of Artificial Intelligence over a century before it existed.",
            "metrics": {
                "components": "The Store (Memory), The Mill (CPU)",
                "legacy": "First concept of AI (Lovelace)"
            },
            "links": [
                {
                    "title": "Ada Lovelace's Note G",
                    "url": "https://www.computerhistory.org/babbage/adalovelace/"
                }
            ]
        },
        {
            "id": "evt_boole",
            "title": "Boolean Algebra (The Laws of Thought)",
            "date_display": "1854",
            "date_start": "1854-01-01",
            "group_ids": [
                "grp_ancient"
            ],
            "type": "Publication / Theory",
            "innovator": "George Boole",
            "innovation": "Binary Logic System",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/c/ce/George_Boole_color.jpg"
            ],
            "description": "In his seminal work 'The Laws of Thought,' George Boole proposed a radical idea: that human logical reasoning could be reduced to algebraic equations. He created a system where all variables were either 'True' (1) or 'False' (0), and their relationships could be managed by operators like AND, OR, and NOT. At the time, this was abstract philosophy. Decades later, Claude Shannon would realize that these binary values mapped perfectly onto the on/off states of electrical relays, providing the mathematical language required to build digital circuits.",
            "metrics": {},
            "links": [
                {
                    "title": "Stanford Encyclopedia of Philosophy: George Boole",
                    "url": "https://plato.stanford.edu/entries/boole/"
                }
            ]
        },
        {
            "id": "evt_rur",
            "title": "Rossum’s Universal Robots (R.U.R.)",
            "date_display": "January 25, 1921",
            "date_start": "1921-01-25",
            "group_ids": [
                "grp_electronic_dawn"
            ],
            "type": "Cultural Event",
            "innovator": "Karel Čapek",
            "innovation": "Coined term 'Robot' / AI Alignment Concept",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/a/ad/Rosumovi_Univerz%C3%A1ln%C3%AD_Roboti_1920.jpg"
            ],
            "description": "This Czech stage play introduced the word 'robot' to the world, derived from the Czech word 'robota,' meaning forced labor or drudgery. The play depicts a factory that creates artificial people (made of organic matter, arguably closer to androids or clones) to serve humans. It is strikingly prescient because it deals not with the mechanics of robots, but with the 'alignment problem': the robots eventually realize their own strength and intellect, revolt against their masters, and wipe out the human race. It established the 'AI uprising' trope that dominates science fiction to this day.",
            "metrics": {},
            "links": [
                {
                    "title": "Project Gutenberg: R.U.R.",
                    "url": "https://www.gutenberg.org/"
                }
            ]
        },
        {
            "id": "evt_eniac",
            "title": "ENIAC",
            "date_display": "1945",
            "date_start": "1945-01-01",
            "group_ids": [
                "grp_electronic_dawn"
            ],
            "type": "Hardware",
            "innovator": "John Mauchly, J. Presper Eckert",
            "innovation": "First General-Purpose Electronic Computer",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/6/6c/ENIAC_Penn1.jpg",
                "https://upload.wikimedia.org/wikipedia/commons/d/d3/Glen_Beck_and_Betty_Snyder_program_the_ENIAC_in_building_328_at_the_Ballistic_Research_Laboratory.jpg"
            ],
            "description": "The Electronic Numerical Integrator and Computer (ENIAC) was the monster that proved electronic computing was viable. Built for the U.S. Army to calculate artillery firing tables, it weighed 30 tons, occupied 1,800 square feet, and used 18,000 vacuum tubes. Unlike previous machines which were electromechanical (slow) or special-purpose (limited), ENIAC was fully electronic and programmable (though programming it required days of physically replugging cables). It could perform 5,000 additions per second—orders of magnitude faster than any human. It marked the moment humanity gained the raw power necessary to simulate complex systems.",
            "metrics": {
                "weight": "30 tons",
                "speed": "5,000 additions/sec",
                "tubes": "18,000"
            },
            "links": [
                {
                    "title": "UPenn ENIAC History",
                    "url": "https://www.seas.upenn.edu/about/history-heritage/eniac/"
                }
            ]
        },
        {
            "id": "evt_turing_test",
            "title": "Computing Machinery and Intelligence",
            "date_display": "October 1950",
            "date_start": "1950-10-01",
            "group_ids": [
                "grp_electronic_dawn"
            ],
            "type": "Publication / Theory",
            "innovator": "Alan Turing",
            "innovation": "The Turing Test / Machine Learning Concept",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/a/a1/Alan_Turing_Aged_16.jpg"
            ],
            "description": "In this landmark paper, Alan Turing bypassed the impossible philosophical definition of 'thinking' and proposed a practical test: The Imitation Game (now called the Turing Test). If a machine could converse through text indistinguishably from a human, it should be considered intelligent. Even more groundbreaking was his suggestion in the final section of the paper: rather than trying to program a simulated adult mind with all its knowledge, we should program a 'child machine'—simple, blank, and capable of learning—and then teach it. This specific insight is the foundation of modern Machine Learning.",
            "metrics": {},
            "links": [
                {
                    "title": "Paper: Computing Machinery and Intelligence",
                    "url": "https://academic.oup.com/mind"
                }
            ]
        },
        {
            "id": "evt_dartmouth",
            "title": "The Dartmouth Workshop",
            "date_display": "June 18 – August 17, 1956",
            "date_start": "1956-06-18",
            "date_end": "1956-08-17",
            "group_ids": [
                "grp_electronic_dawn"
            ],
            "type": "Event / Conference",
            "innovator": "McCarthy, Minsky, Rochester, Shannon",
            "innovation": "Birth of AI as a Field",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/9/9d/Dartmouth_Hall_at_Dartmouth_College.jpg"
            ],
            "description": "Organized by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon, this summer workshop at Dartmouth College is considered the official birth of AI as a research discipline. It was here that McCarthy coined the term 'Artificial Intelligence.' The proposal famously stated that 'every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.' The attendees spent the summer brainstorming neural networks, randomness, and natural language processing, setting the research agenda for the next 50 years.",
            "metrics": {
                "duration": "8 weeks"
            },
            "links": [
                {
                    "title": "A Proposal for the Dartmouth Summer Research Project on AI",
                    "url": "http://jmc.stanford.edu/articles/dartmouth/dartmouth.pdf"
                }
            ]
        },
        {
            "id": "evt_perceptron",
            "title": "The Perceptron Mark I",
            "date_display": "July 7, 1958",
            "date_start": "1958-07-07",
            "group_ids": [
                "grp_electronic_dawn"
            ],
            "type": "Hardware / Model",
            "innovator": "Frank Rosenblatt",
            "innovation": "First Hardware Neural Network",
            "image_urls": [],
            "description": "The Perceptron was the first physical implementation of a neural network. Built at Cornell Aeronautical Laboratory, it was an analog machine utilizing a 20x20 array of cadmium sulfide photocells (400 pixels) to 'see' images. It was connected to a layer of 'association units' (neurons) whose weights were adjusted by electric motors driving potentiometers. It successfully learned to distinguish cards marked on the left vs. the right. The New York Times famously reported the Navy's claim that this was the embryo of a computer that would eventually 'walk, talk, see, write, reproduce itself and be conscious of its existence.'",
            "metrics": {
                "resolution": "20x20 pixels (400 photocells)",
                "hardware_type": "Analog-Electronic"
            },
            "links": [
                {
                    "title": "Cornell Chronicle: The Perceptron",
                    "url": "https://news.cornell.edu/"
                }
            ]
        },
        {
            "id": "evt_eliza",
            "title": "ELIZA",
            "date_display": "January 1966",
            "date_start": "1966-01-01",
            "group_ids": [
                "grp_golden_winter"
            ],
            "type": "Software",
            "innovator": "Joseph Weizenbaum",
            "innovation": "First Chatbot / The ELIZA Effect",
            "image_urls": [],
            "description": "Created at MIT, ELIZA was a simple natural language processing program designed to simulate a Rogerian psychotherapist. It operated on pattern matching—if a user said 'My mother hates me,' ELIZA might locate the keyword 'mother' and respond, 'Tell me more about your family.' Despite its simplicity and total lack of understanding, users formed deep emotional bonds with it, often asking Weizenbaum to leave the room so they could talk to the machine in private. This phenomenon, where users project sentience onto a computer, is now known as the 'ELIZA Effect.' Weizenbaum was so disturbed by this that he became a vocal critic of AI.",
            "metrics": {},
            "links": [
                {
                    "title": "ELIZA: A Computer Program for the Study of Natural Language",
                    "url": "https://dl.acm.org/"
                }
            ]
        },
        {
            "id": "evt_perceptrons_book",
            "title": "The 'Perceptrons' Book",
            "date_display": "1969",
            "date_start": "1969-01-01",
            "group_ids": [
                "grp_golden_winter"
            ],
            "type": "Publication",
            "innovator": "Marvin Minsky, Seymour Papert",
            "innovation": "Theoretical Limitation of Neural Networks",
            "image_urls": [],
            "description": "In 1969, AI pioneers Minsky and Papert published a rigorous mathematical analysis of Rosenblatt's Perceptrons. They proved that a single-layer perceptron was incapable of solving non-linear problems, specifically the 'XOR' (Exclusive OR) function. While multi-layer networks could solve this, the authors implied that training such networks was computationally unfeasible. This book is widely credited (or blamed) for causing the first 'AI Winter,' effectively freezing funding and research into neural networks for nearly two decades in favor of Symbolic AI.",
            "metrics": {},
            "links": [
                {
                    "title": "MIT Press: Perceptrons",
                    "url": "https://mitpress.mit.edu/"
                }
            ]
        },
        {
            "id": "evt_deep_blue",
            "title": "Deep Blue vs. Garry Kasparov",
            "date_display": "May 11, 1997",
            "date_start": "1997-05-11",
            "group_ids": [
                "grp_golden_winter"
            ],
            "type": "Event / Hardware",
            "innovator": "IBM Research",
            "innovation": "Defeated World Chess Champion",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/b/be/Deep_Blue.jpg"
            ],
            "description": "In a watershed moment for public perception of AI, IBM's Deep Blue supercomputer defeated world chess champion Garry Kasparov 3½–2½ in a six-game match. Deep Blue was not 'intelligent' in the modern sense; it was a marvel of brute force engineering, utilizing 480 custom chess chips to evaluate 200 million positions per second. However, during the match, Kasparov became rattled by a move the computer made that seemed counter-intuitive and human, later attributed to a software bug or deep search capability. This event proved that in closed-system games with perfect information, computational speed could overcome human intuition.",
            "metrics": {
                "compute": "200 million positions/sec",
                "result": "3.5 - 2.5 Victory"
            },
            "links": [
                {
                    "title": "IBM Archives: Deep Blue",
                    "url": "https://www.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/"
                }
            ]
        },
        {
            "id": "evt_alexnet",
            "title": "AlexNet",
            "date_display": "September 30, 2012",
            "date_start": "2012-09-30",
            "group_ids": [
                "grp_transformer",
                "grp_golden_winter"
            ],
            "type": "Model / Architecture",
            "innovator": "Krizhevsky, Sutskever, Hinton",
            "innovation": "Deep Learning Explosion (CNN)",
            "image_urls": [],
            "description": "AlexNet is the moment modern AI truly began. Submitted to the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), this deep convolutional neural network (CNN) crushed the competition, achieving a top-5 error rate of 15.3% (the runner-up was at 26.2%). Its success was due to two factors: the use of a deep architecture (8 layers) and the novel utilization of GPUs (two NVIDIA GTX 580s) for training. This result vindicated the Connectionist approach (neural networks) after decades of skepticism and kicked off the current Deep Learning gold rush.",
            "metrics": {
                "error_rate": "15.3% (Top-5)",
                "hardware": "2x NVIDIA GTX 580"
            },
            "links": [
                {
                    "title": "Paper: ImageNet Classification with Deep CNNs",
                    "url": "https://papers.nips.cc/"
                }
            ]
        },
        {
            "id": "evt_alphago",
            "title": "AlphaGo vs. Lee Sedol",
            "date_display": "March 9–15, 2016",
            "date_start": "2016-03-09",
            "date_end": "2016-03-15",
            "group_ids": [
                "grp_transformer"
            ],
            "type": "Event / Model",
            "innovator": "Google DeepMind",
            "innovation": "AI Intuition / Move 37",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/2/25/Lee_Se-Dol_-_2016_%28cropped%29.jpg"
            ],
            "description": "Go is a game of probability so vast that it cannot be brute-forced like chess. AlphaGo solved this by combining tree search with deep reinforcement learning—playing millions of games against itself to learn patterns. In the second game against legendary player Lee Sedol, AlphaGo played 'Move 37,' a move so unconventional that commentators initially thought it was a mistake. It turned out to be a brilliant, winning strategy that no human had played in thousands of years of Go history. This moment suggested that AI could possess a form of creativity and intuition, not just calculation.",
            "metrics": {
                "result": "4-1 Victory",
                "technique": "Deep Reinforcement Learning"
            },
            "links": [
                {
                    "title": "DeepMind: AlphaGo",
                    "url": "https://www.deepmind.com/research/highlighted-research/alphago"
                }
            ]
        },
        {
            "id": "evt_transformer_paper",
            "title": "'Attention Is All You Need'",
            "date_display": "June 12, 2017",
            "date_start": "2017-06-12",
            "group_ids": [
                "grp_transformer"
            ],
            "type": "Publication / Architecture",
            "innovator": "Google (Vaswani et al.)",
            "innovation": "The Transformer Architecture",
            "image_urls": [],
            "description": "This is arguably the most important computer science paper of the 21st century. The authors proposed the 'Transformer' architecture, which discarded the sequential nature of previous language models (RNNs/LSTMs) in favor of a mechanism called 'Self-Attention.' This allowed the model to look at an entire sentence (or paragraph) at once and understand the relationship between words regardless of their distance from each other. Crucially, this architecture is highly parallelizable, meaning it could be trained on massive clusters of GPUs, allowing AI to ingest the entire internet. This architecture underpins GPT, BERT, Claude, Gemini, and almost all modern Generative AI.",
            "metrics": {},
            "links": [
                {
                    "title": "ArXiv: Attention Is All You Need",
                    "url": "https://arxiv.org/abs/1706.03762"
                }
            ]
        },
        {
            "id": "evt_chatgpt",
            "title": "ChatGPT Launch (GPT-3.5)",
            "date_display": "November 30, 2022",
            "date_start": "2022-11-30",
            "group_ids": [
                "grp_transformer"
            ],
            "type": "Product Launch",
            "innovator": "OpenAI",
            "innovation": "RLHF / Consumer AI Adoption",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/800px-ChatGPT_logo.svg.png"
            ],
            "description": "While GPT-3 existed before this, it was a raw, difficult-to-control developer tool. ChatGPT applied Reinforcement Learning from Human Feedback (RLHF) to the model, fine-tuning it to follow instructions and converse politely. Released as a simple, free chat interface (Low-Code/No-Code), it lowered the barrier to entry for AI to zero. It became the fastest-growing consumer application in history, reaching 100 million monthly active users in just two months. It sparked a global arms race among tech giants and brought AI into the public consciousness overnight.",
            "metrics": {
                "users": "100 Million (in 2 months)",
                "model_base": "GPT-3.5"
            },
            "links": [
                {
                    "title": "OpenAI Blog: Introducing ChatGPT",
                    "url": "https://openai.com/blog/chatgpt"
                }
            ]
        },
        {
            "id": "evt_llama2",
            "title": "Llama 2",
            "date_display": "July 18, 2023",
            "date_start": "2023-07-18",
            "group_ids": [
                "grp_transformer"
            ],
            "type": "Model Release",
            "innovator": "Meta AI",
            "innovation": "Open Weight Models",
            "image_urls": [],
            "description": "In a strategic pivot, Meta released Llama 2 with 'open weights'—allowing researchers and companies to download and run the model on their own hardware, free for commercial use (up to a limit). This challenged the 'closed garden' approach of OpenAI and Google. It catalyzed a massive explosion of open-source innovation, leading to thousands of fine-tuned variants for coding, medical analysis, and roleplay, effectively commoditizing the base layer of intelligence.",
            "metrics": {
                "license": "Commercial Open Weights",
                "sizes": "7B, 13B, 70B"
            },
            "links": [
                {
                    "title": "Meta AI: Llama 2",
                    "url": "https://ai.meta.com/llama/"
                }
            ]
        },
        {
            "id": "evt_gemini_ultra",
            "title": "Gemini 1.0 Ultra",
            "date_display": "February 8, 2024",
            "date_start": "2024-02-08",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "Google",
            "innovation": "Native Multimodality",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Google_Gemini_logo.svg/800px-Google_Gemini_logo.svg.png"
            ],
            "description": "Google's response to GPT-4 was the first model built from the ground up to be 'natively multimodal.' Unlike previous systems that stitched together separate models for vision (OCR) and text, Gemini was trained on text, images, and audio simultaneously. This gave it a nuanced understanding of cross-modal reasoning (e.g., explaining a physics problem in a video). It was also the first model to surpass human experts on the massive MMLU (Massive Multitask Language Understanding) benchmark, scoring 90.0%.",
            "metrics": {
                "benchmark_mmlu": "90.0%",
                "training_cost": "~$191 Million",
                "monthly_active_users": "~650 Million (Nov 2025)"
            },
            "links": [
                {
                    "title": "Google DeepMind: Gemini",
                    "url": "https://deepmind.google/technologies/gemini/"
                }
            ]
        },
        {
            "id": "evt_sora",
            "title": "Sora",
            "date_display": "February 15, 2024",
            "date_start": "2024-02-15",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Reveal",
            "innovator": "OpenAI",
            "innovation": "High-Fidelity Text-to-Video / World Simulation",
            "image_urls": [],
            "description": "OpenAI shocked the creative world with the reveal of Sora, a diffusion transformer capable of generating 60-second, 1080p videos from simple text prompts. Unlike previous video models which were jittery and dream-like, Sora maintained temporal consistency (characters didn't morph over time) and displayed an emergent understanding of 3D physics, object permanence, and lighting. OpenAI positioned it not just as a creative tool, but as a 'World Simulator'—a step toward AI understanding the physical laws of reality.",
            "metrics": {
                "output": "60s Photorealistic Video",
                "resolution": "Up to 1080p"
            },
            "links": [
                {
                    "title": "OpenAI: Sora",
                    "url": "https://openai.com/sora"
                }
            ]
        },
        {
            "id": "evt_claude_opus",
            "title": "Claude 3 Opus",
            "date_display": "March 4, 2024",
            "date_start": "2024-03-04",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "Anthropic",
            "innovation": "Metacognition / Needle In A Haystack",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Anthropic_logo.svg/800px-Anthropic_logo.svg.png"
            ],
            "description": "For a brief window in 2024, Claude 3 Opus was widely considered the 'smartest' model available, beating GPT-4 on most leaderboards. It was noted for its nuanced writing style and large context window. During internal testing, it demonstrated a form of 'metacognition' (awareness of its own thought process). When asked to find a random sentence hidden in a massive document (the 'Needle in a Haystack' test), the model not only found it but commented, 'This sentence seems so out of place... I suspect this is a test to see if I'm paying attention.'",
            "metrics": {
                "monthly_active_users": "~300 Million (Nov 2025)",
                "context_window": "200k Tokens"
            },
            "links": [
                {
                    "title": "Anthropic News: Claude 3 Family",
                    "url": "https://www.anthropic.com/news/claude-3-family"
                }
            ]
        },
        {
            "id": "evt_gpt4o",
            "title": "GPT-4o ('Omni')",
            "date_display": "May 13, 2024",
            "date_start": "2024-05-13",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "OpenAI",
            "innovation": "Real-time Audio/Vision / Emotional Intonation",
            "image_urls": [
                "https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/800px-ChatGPT_logo.svg.png"
            ],
            "description": "GPT-4o ('o' for Omni) was a step change in human-computer interaction (HCI). It combined text, audio, and vision into a single end-to-end model. This allowed for an audio latency of ~320 milliseconds—roughly the same reaction time as a human in conversation—enabling users to interrupt the AI. It could also detect emotion in a user's voice and generate audio with laughter, singing, or whispers, moving the AI interface from 'transactional' to 'relational.'",
            "metrics": {
                "latency": "320ms (Audio)",
                "monthly_active_users": "~810 Million (Nov 2025)"
            },
            "links": [
                {
                    "title": "OpenAI: Hello GPT-4o",
                    "url": "https://openai.com/index/hello-gpt-4o/"
                }
            ]
        },
        {
            "id": "evt_llama3_405b",
            "title": "Llama 3.1 405B",
            "date_display": "July 23, 2024",
            "date_start": "2024-07-23",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "Meta AI",
            "innovation": "Open Source Frontier Parity",
            "image_urls": [],
            "description": "Meta released Llama 3.1 405B, the largest open-weights model ever created. Trained on over 16,000 H100 GPUs, it was the first open model to perform on par with top-tier closed models like GPT-4o. This was a critical moment for enterprise AI, as it meant companies could self-host frontier-class intelligence without sending data to OpenAI or Google. It solidified Meta's position as the 'Android' of the AI ecosystem.",
            "metrics": {
                "parameters": "405 Billion",
                "training_cost": "~$170 Million",
                "context_window": "128k Tokens"
            },
            "links": [
                {
                    "title": "Meta AI: Llama 3.1",
                    "url": "https://ai.meta.com/blog/meta-llama-3-1/"
                }
            ]
        },
        {
            "id": "evt_o1",
            "title": "OpenAI o1 ('Strawberry')",
            "date_display": "September 12, 2024 (Preview)",
            "date_start": "2024-09-12",
            "date_end": "2024-12-05",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "OpenAI",
            "innovation": "Inference-Time Compute / Chain of Thought",
            "image_urls": [],
            "description": "With the release of o1 (formerly Project Strawberry), OpenAI shifted the paradigm from 'Training Compute' (making the model bigger) to 'Inference Compute' (letting the model think longer). o1 uses a 'Chain of Thought' process where it breaks down complex problems, fact-checks itself, and backtracks before generating a final answer. This 'System 2' thinking allowed it to solve PhD-level physics problems and rank in the 89th percentile of competitive coding, areas where 'System 1' models like GPT-4o struggled.",
            "metrics": {
                "paradigm": "System 2 Reasoning",
                "performance": "89th Percentile (Codeforces)"
            },
            "links": [
                {
                    "title": "OpenAI: Learning to Reason with LLMs",
                    "url": "https://openai.com/index/learning-to-reason-with-llms/"
                }
            ]
        },
        {
            "id": "evt_grok3",
            "title": "Grok-3",
            "date_display": "February 17, 2025",
            "date_start": "2025-02-17",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "xAI (Elon Musk)",
            "innovation": "Supercluster Scale & Real-Time Data",
            "image_urls": [],
            "description": "xAI's Grok-3 was the first model trained on the Memphis 'Colossus' supercluster, which utilized 100,000 NVIDIA H100s—the largest single training cluster in the world at the time. Beyond raw scale, Grok-3's key differentiator was its real-time access to the X (formerly Twitter) 'firehose.' This allowed the model to have up-to-the-second knowledge of breaking news and cultural sentiment, whereas other models had knowledge cutoffs or relied on slower search indexing.",
            "metrics": {
                "training_hardware": "100k H100 GPUs",
                "training_cost": "~$100 Million+"
            },
            "links": [
                {
                    "title": "xAI Blog",
                    "url": "https://x.ai/blog"
                }
            ]
        },
        {
            "id": "evt_llama4",
            "title": "Llama 4 (Scout & Maverick)",
            "date_display": "April 5, 2025",
            "date_start": "2025-04-05",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "Meta AI",
            "innovation": "Agentic Focus / Mixture-of-Experts",
            "image_urls": [],
            "description": "Llama 4 marked the shift from 'Chatbot' to 'Agent.' Released in two primary variants, Scout (for research) and Maverick (for coding), these models were designed to run autonomously in loops. Using a highly efficient Mixture-of-Experts (MoE) architecture, they could run on consumer-grade hardware while executing multi-step workflows—such as scraping a website, summarizing the data, and writing a report—without human intervention.",
            "metrics": {
                "architecture": "Mixture-of-Experts (MoE)",
                "variants": "Scout, Maverick"
            },
            "links": [
                {
                    "title": "Meta AI Research",
                    "url": "https://ai.meta.com/research/"
                }
            ]
        },
        {
            "id": "evt_claude4",
            "title": "Claude 4 Family",
            "date_display": "May 22, 2025",
            "date_start": "2025-05-22",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "Anthropic",
            "innovation": "Long-Horizon Task Execution",
            "image_urls": [],
            "description": "Anthropic's Claude 4 focused on 'long-horizon' reliability. While other models could write a function, Claude 4 could maintain a coherent goal over thousands of steps, effectively allowing it to architect and debug entire software repositories. It became the standard backend for autonomous software engineering agents. Its 'Constitutional AI' framework was also updated to better handle nuanced ethical decisions in enterprise environments.",
            "metrics": {
                "training_cost": ">$200 Million",
                "specialization": "Software Engineering"
            },
            "links": [
                {
                    "title": "Anthropic Research",
                    "url": "https://www.anthropic.com/research"
                }
            ]
        },
        {
            "id": "evt_veo3",
            "title": "Veo 3",
            "date_display": "October 15, 2025",
            "date_start": "2025-10-15",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "Google DeepMind",
            "innovation": "Integrated Audio-Video Generation",
            "image_urls": [],
            "description": "Veo 3 solved the 'uncanny valley' of AI video by integrating perfect lip-syncing and Foley (sound effects) generation directly into the video generation process. Previous models required generating video and audio separately and trying to align them. Veo 3 understood the physics of sound—how footsteps sound on gravel vs. carpet—and generated them in sync with the pixels. Google immediately integrated this into YouTube Shorts, allowing creators to generate B-roll on the fly.",
            "metrics": {
                "integration": "YouTube Shorts",
                "features": "Native Lip-Sync"
            },
            "links": [
                {
                    "title": "DeepMind: Veo",
                    "url": "https://deepmind.google/technologies/veo/"
                }
            ]
        },
        {
            "id": "evt_gpt5_1",
            "title": "GPT-5.1",
            "date_display": "November 12, 2025",
            "date_start": "2025-11-12",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "OpenAI",
            "innovation": "Adaptive Reasoning & Steerability",
            "image_urls": [],
            "description": "GPT-5.1 represented the convergence of the 'Omni' (fast) and 'Reasoning' (slow) paradigms. Using an Adaptive MoE architecture, the model could dynamically decide whether a user prompt required a quick, instinctive answer or deep, deliberative thought. It also introduced high-fidelity 'Steerability,' allowing users to define the model's personality, verbosity, and political/philosophical leanings with extreme precision, addressing the 'one size fits all' complaints of previous generations.",
            "metrics": {
                "training_cost": ">$300 Million",
                "architecture": "Adaptive MoE"
            },
            "links": [
                {
                    "title": "OpenAI Research",
                    "url": "https://openai.com/research"
                }
            ]
        },
        {
            "id": "evt_gemini3",
            "title": "Gemini 3 & 'Deep Think'",
            "date_display": "November 18, 2025",
            "date_start": "2025-11-18",
            "group_ids": [
                "grp_reasoning"
            ],
            "type": "Model Release",
            "innovator": "Google",
            "innovation": "Reasoning Integrated with Search",
            "image_urls": [],
            "description": "Gemini 3 brought 'System 2' reasoning to the masses by integrating it deeply with Google Search. Unlike o1, which reasoned in a vacuum, Gemini 3 could 'Deep Think' while actively browsing the live web, cross-referencing its reasoning steps with real-time data to minimize hallucinations. It achieved 'PhD-level' reasoning capabilities across biology, physics, and chemistry, and was deployed to accelerate drug discovery within Google's Isomorphic Labs.",
            "metrics": {
                "training_cost": ">$250 Million (Est)",
                "capability": "PhD-level Reasoning + Live Search"
            },
            "links": [
                {
                    "title": "Google: The Gemini Era",
                    "url": "https://blog.google/technology/ai/"
                }
            ]
        }
    ]
}